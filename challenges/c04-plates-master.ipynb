{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "western-institution",
   "metadata": {},
   "source": [
    "# c05-plates\n",
    "\n",
    "*Purpose*: Variability in engineering systems exposes us to risk. To rigorously design for variability, we need to analyze data, model the variability, and study its effects on system performance. To practice this entire process, you will study the structural safety of a plate subject to buckling loads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-peninsula",
   "metadata": {},
   "source": [
    "## Informed Consent\n",
    "\n",
    "As a reminder, this course is part of a study of engineers' behavior. While not all parts of the course include data collection, we will analyze your responses to this homework as part of the research.\n",
    "\n",
    "We will analyze your answers to this homework, and may quote this work as part of published research.\n",
    "\n",
    "You can ask to have your responses excluded from the study after the interview by sending us an email. Before starting this assignment, do you consent to sharing your work with the study?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-redhead",
   "metadata": {},
   "source": [
    "I agree to share my responses with the study\n",
    "\n",
    "- (Please type your name here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "import pandas as pd\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline\n",
    "\n",
    "# For assertion\n",
    "from pandas.api.types import is_numeric_dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-terror",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This challenge continues the `c03-stang` challenge; we will start from the same dataset but will apply ideas of modeling and design under uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-terrorist",
   "metadata": {},
   "source": [
    "# Assess Statistical Control\n",
    "\n",
    "Before we studied the Stang et al. dataset using generic EDA techniques; let's revisit this dataset armed with the knowledge of statistical process monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-console",
   "metadata": {},
   "source": [
    "### __q1__ Assess statistical control of `E` across thicknesses\n",
    "\n",
    "Construct a control chart with groupings according to plate thickness. Assess the state of statistical control of the elasticity. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Construct a control chart\n",
    "(\n",
    "    df_stang\n",
    "# solution-begin\n",
    "    >> gr.pt_xbs(group=\"thick\", var=\"E\")\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-singles",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is the variability of `E` under statistical control across plate thicknesses? How do you know?\n",
    "  - (Your response here)\n",
    "- Is the mean of `E` under statistical control across plate thicknesses? How do you know?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is the variability of `E` under statistical control? How do you know?\n",
    "  - Likely yes; the points are all within the control limits and there are no patterns in the data.\n",
    "- Is the mean of `E` under statistical control? How do you know?\n",
    "  - No; there are several violations of the control limits. In particular, the thickest plates have a much lower elasticity than the other specimens.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-demand",
   "metadata": {},
   "source": [
    "## Follow-up experiment\n",
    "\n",
    "We've seen that the Stang et al. data are certainly *not* under statistical control (and we have some hints as to what went wrong!). Let's imagine that manufacturing of these plates has ramped up, and we have access to a much larger dataset from this production line.\n",
    "\n",
    "*Note*: The following data were simulated; they do not correspond to physical experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"./data/c05-data.csv\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-vintage",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Here is a data dictionary for the new `df_data`.\n",
    "\n",
    "| Symbol | Variable | Meaning |\n",
    "|---|---|---|\n",
    "| `E` | Elasticity (ksi) | Mechanical property |\n",
    "| `mu` | Poisson's ratio (-) | Mechanical property |\n",
    "| `t` | Thickness (in) | Geometric property |\n",
    "| `id_machine` | Machine identifier | Manufacturing variable |\n",
    "| `id_specimen` | Specimen identifier | Manufacturing variable |\n",
    "| `id_measurement` | Measurement (operator) identifier | Manufacturing variable |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-touch",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __q2__ Explore the experimental design\n",
    "\n",
    "Answer the following questions to better understand the experimental design. Note that the same questions are posed within each cell and under *observations* below.\n",
    "\n",
    "*Hint*: The verbs `tf_count()` and `tf_distinct()` will be very useful for answering some of these questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: What thicknesses were tested?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_count(DF.t)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many unique specimens were manufactured?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_summarize(spec_max=gr.max(DF.id_specimen) + 1)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many specimens were made on each machine?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_distinct(DF.id_specimen, DF.id_machine)\n",
    "    >> gr.tf_count(DF.id_machine)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many times did each operator measure each specimen?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_count(DF.id_specimen, DF.id_measurement)\n",
    "    >> gr.tf_summarize(n_max=gr.max(DF.n))\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-carnival",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What thicknesses were tested?\n",
    "  - (Your response here)\n",
    "- How many unique specimens were manufactured?\n",
    "  - (Your response here)\n",
    "- How many specimens were made on each machine?\n",
    "  - (Your response here)\n",
    "- How many times did each operator measure each specimen?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What thicknesses were tested?\n",
    "  - 0.125 and 0.250 inches\n",
    "- How many unique specimens were manufactured?\n",
    "  - 120\n",
    "- How many specimens were made on each machine?\n",
    "  - 20 specimens each\n",
    "- How many times did each operator measure each specimen?\n",
    "  - Just once\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-style",
   "metadata": {},
   "source": [
    "### __q3__ Compare across thicknesses\n",
    "\n",
    "Compare the elasticity across plate thicknesses; does elasticity seem to be consistent across thickness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compare elasticity across thicknesses\n",
    "## NOTE: There are many ways to do this!\n",
    "(\n",
    "    df_data\n",
    "# solution-begin\n",
    "    >> gr.ggplot(gr.aes(\"t\", \"E\"))\n",
    "    + gr.geom_boxplot(gr.aes(group=\"t\"), notch=True)\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-universal",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is thickness consistent across plate thickness?\n",
    "  - (Your response here)\n",
    "- Will it be reasonable to group together plates of different thicknesses when assessing statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is thickness consistent across plate thickness?\n",
    "  - No; from the plot above, we can see a significant difference in median plate elasticity across thickness.\n",
    "- Will it be reasonable to group together plates of different thicknesses when assessing statistical control? Why or why not?\n",
    "  - No; when assessing statistical control we should use groups within which the behavior is consistent. Since we have identified a strong inconsistency across thickness, each thickness should be treated separately.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-cookbook",
   "metadata": {},
   "source": [
    "### __q4__ Assess statistical control of Poisson's ratio\n",
    "\n",
    "Consider only the `t == 0.250` plates. Assess the state of statistical control of Poisson's ratio. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assess the state of statistical control\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"mu\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-feature",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is `mu` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is `mu` under statistical control? Why or why not?\n",
    "  - Likely yes; there are no patterns in the variability or mean of `mu`.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-cameroon",
   "metadata": {},
   "source": [
    "### __q5__ Assess statistical control of elasticity\n",
    "\n",
    "Consider only the `t == 0.250` plates. Assess the state of statistical control of the elasticity. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assess the state of statistical control\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"E\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_machine\", var=\"E\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-librarian",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Why is it important that we limit this analysis to `t == 0.25` plates?\n",
    "  - (Your response here)\n",
    "- Is `E` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "- Based on the group variable(s) you chose, what follow-up investigations should be done?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Why is it important that we limit this analysis to `t == 0.25` plates?\n",
    "  - We saw above that the thinnest `t == 0.125` and thickest `t == 0.25` plates have significantly different mean elasticities. Therefore, it is not valid to lump thin and thick plates in the same group. Limiting to `t == 0.25` plates is one way to avoid this erroneous grouping.\n",
    "- Is `E` under statistical control? Why or why not?\n",
    "  - No; the mean elasticity violates the control limits for Machines C and D, and the variability of elasticity violates the UCL for measurement h.\n",
    "- Based on the group variable(s) you chose, what follow-up investigations should be done?\n",
    "  - We should investigate Machines C and D, and operator h.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-serbia",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __q6__ Assess statistical control of elasticity (Pt. 2)\n",
    "\n",
    "Repeat your investigation of statistical control of `E`, but use the filters given below. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Assess statistical control of `E` for the filtered data\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    "# solution-begin\n",
    "    >> gr.pt_xbs(group=\"id_machine\", var=\"E\")\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Assess statistical control of `E` for the filtered data\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    "# solution-begin\n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"E\")\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-norwegian",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- For the set of machines and operators considered, is `E` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- For the set of machines and operators considered, is `E` under statistical control? Why or why not?\n",
    "  - Likely yes; we see no patterns across machines or operators.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-samuel",
   "metadata": {},
   "source": [
    "# Consider Sources of Variability\n",
    "\n",
    "Now that we've found a more stable subset of the data, we can move towards modeling the variability with distributions. However, before we go much further, we should investigate the *sources* of variability in the data. Note that we have access to multiple measurements of the same specimens (identified by `id_measurement`); thus we can use the dataset to approximate the real and erroneous variability in the material properties.\n",
    "\n",
    "For the rest of the exercise, we will consider the following subset of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_sub = (\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-relations",
   "metadata": {},
   "source": [
    "### __q7__ Estimate the real variability\n",
    "\n",
    "Identify the column in `df_sub` that groups together multiple measurements of the same quantity.\n",
    "\n",
    "The code below applies the *mean heuristic* ([e-stat02-source](https://zdelrosario.github.io/evc-course/exercises_solution/d08-e-stat02-source-solution.html#heuristics)) to produce a more stable measurement of `E`, then computes the variance across these more stable measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Apply the Mean Heuristic to group by the appropriate variable\n",
    "df_var_mfg = (\n",
    "    df_sub\n",
    "# task-begin\n",
    "    ## TODO: Group by the appropriate variable\n",
    "# task-end\n",
    "# solution-begin\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "# solution-end\n",
    "    >> gr.tf_summarize(E=gr.mean(DF.E))\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_summarize(E_var_mfg=gr.var(DF.E))\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    abs(df_var_mfg.E_var_mfg[0] - 109670.635716) < 1e-6, \\\n",
    "    \"Incorrect variance; make sure you grouped by the correct variable\"\n",
    "\n",
    "df_var_mfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-diamond",
   "metadata": {},
   "source": [
    "### __q8__ Estimate the measurement variability\n",
    "\n",
    "Estimate the measurement variability in `E` by taking the variance within each specimen. Average these variances to produce a more stable estimate `E_var_meas`. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Estimate the measurement variability\n",
    "df_var_meas = (\n",
    "    df_sub\n",
    "# solution-begin\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "    >> gr.tf_summarize(E_var=gr.var(DF.E))\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_summarize(E_var_meas=gr.mean(DF.E_var))\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    abs(df_var_meas.iloc[0, 0] - 168382.91387) < 1e-6, \\\n",
    "    \"Incorrect variance; make sure you grouped by the correct variable\"\n",
    "\n",
    "df_var_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-mathematics",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- How do `E_var_mfg` (previous task) and `E_var_meas` compare?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- How do `E_var_mfg` (previous task) and `E_var_meas` compare?\n",
    "  - `E_var_mfg ~= 109670` is a bit smaller than `E_var_meas ~= 168383`\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dfbc39-dfe4-4bfa-85d1-2304e932a429",
   "metadata": {},
   "source": [
    "The following code applies the mean heuristic to get more stable measurements for `E` and `mu`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_real = (\n",
    "    df_sub\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "    >> gr.tf_summarize(\n",
    "        mu=gr.mean(DF.mu),\n",
    "        E=gr.mean(DF.E),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-implement",
   "metadata": {},
   "source": [
    "# Model the Variability\n",
    "\n",
    "Now you will construct a model for the variability in `E` and `mu`. You'll use this to assess the structural safety of a plate subject to compressive (buckling) loads.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-database",
   "metadata": {},
   "source": [
    "### __q9__ Assess dependency of `E` and `mu`\n",
    "\n",
    "Assess the dependency between `E` and `mu`. Answer the questions under *observations* below.\n",
    "\n",
    "*Hint*: There are many ways to do this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Assess the dependency between E and mu\n",
    "(\n",
    "    df_sub\n",
    "# solution-begin\n",
    "    >> gr.ggplot(gr.aes(\"E\", \"mu\"))\n",
    "    + gr.geom_point()\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d987ef0-2a9c-488f-898b-b89417633861",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What---if any---dependency do `E` and `mu` exhibit?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What---if any---dependency do `E` and `mu` exhibit?\n",
    "  - `E` and `mu` do not seem to be correlated: no dependency\n",
    "<!-- solution-end -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-hygiene",
   "metadata": {},
   "source": [
    "The following code implements the buckling plate model; you wrote code like this in c03-stang.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "md_plate = (\n",
    "    gr.Model(\"Plate critical buckling stress\")\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            k_cr=(df.m * df.b / df.a + df.a / df.m / df.b)**2\n",
    "        ),\n",
    "        var=[\"a\", \"b\", \"m\"],\n",
    "        out=[\"k_cr\"],\n",
    "        name=\"Shape factor\",\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            sigma_cr=df.k_cr * (3.14**3/12) * df.E*1e3 / (1 - df.mu**2)\n",
    "                    *(df.t / df.b)**2\n",
    "        ),\n",
    "        var=[\"k_cr\", \"E\", \"mu\", \"t\", \"b\"],\n",
    "        out=[\"sigma_cr\"],\n",
    "        name=\"Buckling stress\",\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            g_buckle=df.sigma_cr - 2e5 / df.b / df.t,\n",
    "        ),\n",
    "        var=[\"sigma_cr\", \"b\", \"t\"],\n",
    "        out=[\"g_buckle\"],\n",
    "        name=\"Limit state: Buckling\",\n",
    "    )\n",
    ")\n",
    "\n",
    "md_plate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-sweden",
   "metadata": {},
   "source": [
    "### __q10__ Fit a distribution with all observations\n",
    "\n",
    "Fit a distribution for the inputs `E` and `mu` to `md_plate` using the filtered dataset `df_sub`. Make sure to follow the proper modeling process. Add as many code cells as you need for this task. Answer the questions under *Observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795767a-828c-462c-9f74-0bf4a4317744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution-begin\n",
    "mg_E = gr.marg_fit(\"lognorm\", df_sub.E, floc=0)\n",
    "\n",
    "(\n",
    "    df_sub\n",
    "    >> gr.tf_mutate(\n",
    "        q_E=gr.qqvals(DF.E, marg=mg_E),\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"q_E\", \"E\"))\n",
    "    + gr.geom_abline(intercept=0, slope=1, linetype=\"dashed\")\n",
    "    + gr.geom_point()\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663c92f-cf92-44a1-be0c-d050e49faa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution-begin\n",
    "mg_mu = gr.marg_fit(\"lognorm\", df_sub.mu, floc=0)\n",
    "\n",
    "(\n",
    "    df_sub\n",
    "    >> gr.tf_mutate(\n",
    "        q_mu=gr.qqvals(DF.mu, marg=mg_mu),\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"q_mu\", \"mu\"))\n",
    "    + gr.geom_abline(intercept=0, slope=1, linetype=\"dashed\")\n",
    "    + gr.geom_point()\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Add your distribution model to `md_total`\n",
    "md_total = (\n",
    "    md_plate\n",
    "# solution-begin\n",
    "    >> gr.cp_marginals(\n",
    "        E=gr.marg_fit(\"lognorm\", df_sub.E, floc=0),\n",
    "        mu=gr.marg_fit(\"lognorm\", df_sub.mu, floc=0),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    "# solution-end\n",
    ")\n",
    "md_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caaabf6-0539-4e98-932b-6644d3051749",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What assumptions / choices did you make in your model?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What assumptions / choices did you make in your model?\n",
    "  - I assumed a \"lognorm\" distribution for both `E` and `mu`, and assumed independence between the two variables.\n",
    "<!-- solution-end -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-table",
   "metadata": {},
   "source": [
    "### __q11__ Fit a distribution with averaged observations\n",
    "\n",
    "Re-fit the same model you defined above, but use the averaged observations `df_real` instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Add your distribution model to `md_real`, using `df_real` in the fit\n",
    "md_real = (\n",
    "    md_plate\n",
    "# solution-begin\n",
    "    >> gr.cp_marginals(\n",
    "        E=gr.marg_fit(\"lognorm\", df_real.E, floc=0),\n",
    "        mu=gr.marg_fit(\"lognorm\", df_real.mu, floc=0),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    "# solution-end\n",
    ")\n",
    "md_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-purpose",
   "metadata": {},
   "source": [
    "# Design Under Uncertainty\n",
    "\n",
    "Now that we've built a couple models, we can use them to assess the structural safety of plate designs. We'll start by assessing the safety of a baseline design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d937bb-f412-4236-b106-b805fd34465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit this\n",
    "df_baseline = gr.df_make(t=0.25, a=12.0, b=9.0, m=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-fortune",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __q12__ Assess a baseline design\n",
    "\n",
    "Assess the probability of failure $\\text{pof} = \\mathbb{P}[g \\leq 0]$ according to both `md_total` and `md_baseline`. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Assess the probability of failure\n",
    "df_baseline_total = (\n",
    "    md_total\n",
    "# solution-begin\n",
    "    >> gr.ev_sample(n=1e3, df_det=df_baseline)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_baseline_total, pd.DataFrame), \\\n",
    "    \"df_baseline_total is not a DataFrame; make sure to evaluate the model\"\n",
    "assert \\\n",
    "    \"pof_lo\" in df_baseline_total.columns, \\\n",
    "    \"df_baseline_total does not have a pof_lo column; make sure to include a lower CI end\"\n",
    "assert \\\n",
    "    \"pof_up\" in df_baseline_total.columns, \\\n",
    "    \"df_baseline_total does not have a pof_up column; make sure to include a lower CI end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Assess the probability of failure\n",
    "df_baseline_real = (\n",
    "    md_real\n",
    "# solution-begin\n",
    "    >> gr.ev_sample(n=1e3, df_det=df_baseline)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_baseline_real, pd.DataFrame), \\\n",
    "    \"df_baseline_real is not a DataFrame; make sure to evaluate the model\"\n",
    "assert \\\n",
    "    \"pof_lo\" in df_baseline_real.columns, \\\n",
    "    \"df_baseline_real does not have a pof_lo column; make sure to include a lower CI end\"\n",
    "assert \\\n",
    "    \"pof_up\" in df_baseline_real.columns, \\\n",
    "    \"df_baseline_real does not have a pof_up column; make sure to include a lower CI end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; use this to check your work\n",
    "(\n",
    "    df_baseline_total\n",
    "    >> gr.tf_mutate(model=\"Total\")\n",
    "    >> gr.tf_bind_rows(\n",
    "        df_baseline_real\n",
    "        >> gr.tf_mutate(model=\"Real\")\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"model\", \"pof\"))\n",
    "    + gr.geom_hline(yintercept=0.01, linetype=\"dashed\")\n",
    "    + gr.geom_errorbar(gr.aes(ymin=\"pof_lo\", ymax=\"pof_up\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdae184-b135-477f-ab9d-745c4d0ab071",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- According to the `Total` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - (Your response here)\n",
    "- According to the `Real` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- According to the `Total` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - No; the `Total` model gives a failure rate somewhere between `0.04` and `0.08`.\n",
    "- According to the `Real` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - Likely no; at a sample size of `n=1e3` the confidence interval for the `Real` model includes the target of `0.01`, but based on the evidence, it is possible that `pof > 0.01`.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c7400-e48e-44b4-8195-0d5b5d614fe7",
   "metadata": {},
   "source": [
    "### __q13__ Adjust the design\n",
    "\n",
    "Adjust the thickness of the plate to *confidently* achieve `pof < 0.01`. Repeat this process for both the `Total` and `Real` models. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3b9c1-4967-433c-a6e9-d5fa8f9e787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Adjust the design\n",
    "df_revised_total = gr.df_make(\n",
    "    ## TODO: Adjust the thickness to modify the design\n",
    "# task-begin\n",
    "    # t=0.25,\n",
    "# task-end\n",
    "# solution-begin\n",
    "    t=0.255,\n",
    "# solution-end\n",
    "    ## NOTE: Do not edit the following values\n",
    "    a=12.0, b=9.0, m=1\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit\n",
    "df_revised_total = (\n",
    "    md_total\n",
    "    >> gr.ev_sample(n=1e4, df_det=df_revised_total)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_revised_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2739d-5a45-49cf-912b-e24748ecf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Adjust the design\n",
    "df_revised_real = gr.df_make(\n",
    "    ## TODO: Adjust the thickness to modify the design\n",
    "# task-begin\n",
    "    # t=0.25,\n",
    "# task-end\n",
    "# solution-begin\n",
    "    t=0.251,\n",
    "# solution-end\n",
    "    ## NOTE: Do not edit the following values\n",
    "    a=12.0, b=9.0, m=1\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit\n",
    "df_revised_real = (\n",
    "    md_real\n",
    "    >> gr.ev_sample(n=1e4, df_det=df_revised_real)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_revised_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4a1d0-b78c-4549-bc92-8dcb7a6fbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; the following visual will help you assess the results\n",
    "(\n",
    "    df_revised_total\n",
    "    >> gr.tf_mutate(model=\"Total\")\n",
    "    >> gr.tf_bind_rows(\n",
    "        df_revised_real\n",
    "        >> gr.tf_mutate(model=\"Real\")\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"model\", \"pof\"))\n",
    "    + gr.geom_hline(yintercept=0.01, linetype=\"dashed\")\n",
    "    + gr.geom_errorbar(gr.aes(ymin=\"pof_lo\", ymax=\"pof_up\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ada6af-0fc7-430c-8924-f96a7f9ec9f5",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What needs to be the case with your results to *confidently* conclude that `pof < 0.01`?\n",
    "  - (Your response here)\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Total` model?\n",
    "  - (Your response here)\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Real` model?\n",
    "  - (Your response here)\n",
    "- Suppose the plate manufacturing process can only achieve tolerances to within `0.01` in of thickness. Does distinguishing between real and total variability have a large consequence in this case?\n",
    "  - (Your response here)\n",
    "- Now suppose the plate manufacturing process can achieve tolerances to within `0.001` in of thickness, and weight is a major concern. Does distinguishing between real and total variability have a large consequence in this case?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What needs to be the case with your results to *confidently* conclude that `pof < 0.01`?\n",
    "  - The confidence interval for the POF needs to be entirely below `0.01`.\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Total` model?\n",
    "  - I find `t=0.255`.\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Real` model?\n",
    "  - I find `t=0.251`.\n",
    "- Suppose the plate manufacturing process can only achieve tolerances to within `0.01` in of thickness. Does distinguishing between the `Total` and `Real` model assumptions have a large consequence in this case?\n",
    "  - No; both model assumptions would require `t=0.26` to confidently achieve `pof < 0.01.`\n",
    "- Now suppose the plate manufacturing process can achieve tolerances to within `0.001` in of thickness, and weight is a major concern. Does distinguishing between the `Total` and `Real` model assumptions have a large consequence in this case?\n",
    "  - Yes; under the `Real` model we can shave off a bit more weight, leading to a higher-performance design that still achieves the `pof < 0.01` constraint.\n",
    "<!-- solution-end -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
